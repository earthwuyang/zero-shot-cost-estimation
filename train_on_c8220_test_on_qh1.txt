nohup: ignoring input
Using backend: pytorch
[2024-04-20 19:59:23][DEBUG][train.py:69]:args Namespace(database=<DatabaseSystem.POSTGRES: 'postgres'>, device='cuda:1', experiment_desc='', filename_model='imdb_0', gather_feature_statistics=False, hyperparameter_path='setup/tuned_hyperparameters/tune_est_best_config.json', limit_queries=None, limit_queries_affected_wl=None, loss_class_name='QLoss', max_epoch_tuples=100000, max_no_epochs=None, num_workers=16, plan_featurization='PostgresTrueCardDetail', raw_dir=None, seed=0, skip_train=True, statistics_file='../zero-shot-data/runs_qh1/parsed_plans/statistics_workload_combined.json', target='../zero-shot-data/evaluation/train_on_c8220_test_on_qh1', test_workload_runs=['../zero-shot-data/runs_qh1/parsed_plans/imdb/index_workload_100k_s2_qh1.json', '../zero-shot-data/runs_qh1/parsed_plans/imdb/workload_100k_s1_qh1.json'], train_model=True, workload_runs=['../zero-shot-data/runs/deepdb_augmented/airline/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/airline/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/ssb/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/ssb/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/tpc_h/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/tpc_h/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/walmart/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/walmart/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/financial/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/financial/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/basketball/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/basketball/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/accidents/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/accidents/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/movielens/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/movielens/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/baseball/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/baseball/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/hepatitis/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/hepatitis/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/tournament/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/tournament/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/credit/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/credit/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/employee/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/employee/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/consumer/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/consumer/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/geneea/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/geneea/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/genome/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/genome/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/carcinogenesis/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/carcinogenesis/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/seznam/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/seznam/workload_100k_s1_c8220.json', '../zero-shot-data/runs/deepdb_augmented/fhnk/index_workload_100k_s2_c8220.json', '../zero-shot-data/runs/deepdb_augmented/fhnk/workload_100k_s1_c8220.json'])
[2024-04-20 19:59:23][INFO][train.py:371]:Reading hyperparameters from setup/tuned_hyperparameters/tune_est_best_config.json
[2024-04-20 19:59:23][INFO][train.py:373]:hyperparams {'batch_size': 2048, 'dropout': False, 'final_layers': 4, 'final_width_factor': 1.5, 'hidden_dim': 128, 'lr': 0.001, 'max_emb_dim': 32, 'message_passing_layers': 2, 'node_layers': 4, 'node_type_width_factor': 1.5, 'p_dropout': 0.0, 'plan_featurization_name': 'PostgresEstSystemCardDetail', 'residual': False, 'tree_layer_name': 'MscnConv', 'tree_layer_width_factor': 0.6}
[2024-04-20 20:00:49][INFO][dataset_creation.py:40]:No of Plans: 190000
[2024-04-20 20:00:50][INFO][dataset_creation.py:40]:No of Plans: 4999
[2024-04-20 20:00:51][INFO][dataset_creation.py:40]:No of Plans: 4987
[2024-04-20 20:00:55][INFO][checkpoint.py:123]:No valid checkpoint found Error(s) in loading state_dict for PostgresZeroShotModel:
	size mismatch for node_type_encoders.column.fcout.0.layers.0.weight: copying a param with shape torch.Size([21, 14]) from checkpoint, the shape in current model is torch.Size([16, 11]).
	size mismatch for node_type_encoders.column.fcout.0.layers.0.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([16]).
	size mismatch for node_type_encoders.column.fcout.1.layers.0.weight: copying a param with shape torch.Size([21, 21]) from checkpoint, the shape in current model is torch.Size([16, 16]).
	size mismatch for node_type_encoders.column.fcout.1.layers.0.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([16]).
	size mismatch for node_type_encoders.column.fcout.2.layers.0.weight: copying a param with shape torch.Size([21, 21]) from checkpoint, the shape in current model is torch.Size([16, 16]).
	size mismatch for node_type_encoders.column.fcout.2.layers.0.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([16]).
	size mismatch for node_type_encoders.column.fcout.3.layers.0.weight: copying a param with shape torch.Size([21, 21]) from checkpoint, the shape in current model is torch.Size([16, 16]).
	size mismatch for node_type_encoders.column.fcout.3.layers.0.bias: copying a param with shape torch.Size([21]) from checkpoint, the shape in current model is torch.Size([16]).
	size mismatch for node_type_encoders.column.fcout.4.layers.0.weight: copying a param with shape torch.Size([128, 21]) from checkpoint, the shape in current model is torch.Size([128, 16]).
	size mismatch for node_type_encoders.column.embeddings.data_type.embed.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([7, 7]).
	size mismatch for node_type_encoders.output_column.fcout.0.layers.0.weight: copying a param with shape torch.Size([7, 5]) from checkpoint, the shape in current model is torch.Size([9, 6]).
	size mismatch for node_type_encoders.output_column.fcout.0.layers.0.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for node_type_encoders.output_column.fcout.1.layers.0.weight: copying a param with shape torch.Size([7, 7]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for node_type_encoders.output_column.fcout.1.layers.0.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for node_type_encoders.output_column.fcout.2.layers.0.weight: copying a param with shape torch.Size([7, 7]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for node_type_encoders.output_column.fcout.2.layers.0.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for node_type_encoders.output_column.fcout.3.layers.0.weight: copying a param with shape torch.Size([7, 7]) from checkpoint, the shape in current model is torch.Size([9, 9]).
	size mismatch for node_type_encoders.output_column.fcout.3.layers.0.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([9]).
	size mismatch for node_type_encoders.output_column.fcout.4.layers.0.weight: copying a param with shape torch.Size([128, 7]) from checkpoint, the shape in current model is torch.Size([128, 9]).
	size mismatch for node_type_encoders.output_column.embeddings.aggregation.embed.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([6, 6]).
	size mismatch for node_type_encoders.filter_column.fcout.0.layers.0.weight: copying a param with shape torch.Size([30, 20]) from checkpoint, the shape in current model is torch.Size([34, 23]).
	size mismatch for node_type_encoders.filter_column.fcout.0.layers.0.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([34]).
	size mismatch for node_type_encoders.filter_column.fcout.1.layers.0.weight: copying a param with shape torch.Size([30, 30]) from checkpoint, the shape in current model is torch.Size([34, 34]).
	size mismatch for node_type_encoders.filter_column.fcout.1.layers.0.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([34]).
	size mismatch for node_type_encoders.filter_column.fcout.2.layers.0.weight: copying a param with shape torch.Size([30, 30]) from checkpoint, the shape in current model is torch.Size([34, 34]).
	size mismatch for node_type_encoders.filter_column.fcout.2.layers.0.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([34]).
	size mismatch for node_type_encoders.filter_column.fcout.3.layers.0.weight: copying a param with shape torch.Size([30, 30]) from checkpoint, the shape in current model is torch.Size([34, 34]).
	size mismatch for node_type_encoders.filter_column.fcout.3.layers.0.bias: copying a param with shape torch.Size([30]) from checkpoint, the shape in current model is torch.Size([34]).
	size mismatch for node_type_encoders.filter_column.fcout.4.layers.0.weight: copying a param with shape torch.Size([128, 30]) from checkpoint, the shape in current model is torch.Size([128, 34]).
	size mismatch for node_type_encoders.filter_column.embeddings.operator.embed.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([11, 11]).
	size mismatch for node_type_encoders.filter_column.embeddings.data_type.embed.weight: copying a param with shape torch.Size([10, 10]) from checkpoint, the shape in current model is torch.Size([7, 7]).
	size mismatch for node_type_encoders.plan.fcout.0.layers.0.weight: copying a param with shape torch.Size([36, 24]) from checkpoint, the shape in current model is torch.Size([40, 27]).
	size mismatch for node_type_encoders.plan.fcout.0.layers.0.bias: copying a param with shape torch.Size([36]) from checkpoint, the shape in current model is torch.Size([40]).
	size mismatch for node_type_encoders.plan.fcout.1.layers.0.weight: copying a param with shape torch.Size([36, 36]) from checkpoint, the shape in current model is torch.Size([40, 40]).
	size mismatch for node_type_encoders.plan.fcout.1.layers.0.bias: copying a param with shape torch.Size([36]) from checkpoint, the shape in current model is torch.Size([40]).
	size mismatch for node_type_encoders.plan.fcout.2.layers.0.weight: copying a param with shape torch.Size([36, 36]) from checkpoint, the shape in current model is torch.Size([40, 40]).
	size mismatch for node_type_encoders.plan.fcout.2.layers.0.bias: copying a param with shape torch.Size([36]) from checkpoint, the shape in current model is torch.Size([40]).
	size mismatch for node_type_encoders.plan.fcout.3.layers.0.weight: copying a param with shape torch.Size([36, 36]) from checkpoint, the shape in current model is torch.Size([40, 40]).
	size mismatch for node_type_encoders.plan.fcout.3.layers.0.bias: copying a param with shape torch.Size([36]) from checkpoint, the shape in current model is torch.Size([40]).
	size mismatch for node_type_encoders.plan.fcout.4.layers.0.weight: copying a param with shape torch.Size([128, 36]) from checkpoint, the shape in current model is torch.Size([128, 40]).
	size mismatch for node_type_encoders.plan.embeddings.op_name.embed.weight: copying a param with shape torch.Size([20, 20]) from checkpoint, the shape in current model is torch.Size([23, 23]).
	size mismatch for node_type_encoders.logical_pred.fcout.0.layers.0.weight: copying a param with shape torch.Size([9, 6]) from checkpoint, the shape in current model is torch.Size([18, 12]).
	size mismatch for node_type_encoders.logical_pred.fcout.0.layers.0.bias: copying a param with shape torch.Size([9]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for node_type_encoders.logical_pred.fcout.1.layers.0.weight: copying a param with shape torch.Size([9, 9]) from checkpoint, the shape in current model is torch.Size([18, 18]).
	size mismatch for node_type_encoders.logical_pred.fcout.1.layers.0.bias: copying a param with shape torch.Size([9]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for node_type_encoders.logical_pred.fcout.2.layers.0.weight: copying a param with shape torch.Size([9, 9]) from checkpoint, the shape in current model is torch.Size([18, 18]).
	size mismatch for node_type_encoders.logical_pred.fcout.2.layers.0.bias: copying a param with shape torch.Size([9]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for node_type_encoders.logical_pred.fcout.3.layers.0.weight: copying a param with shape torch.Size([9, 9]) from checkpoint, the shape in current model is torch.Size([18, 18]).
	size mismatch for node_type_encoders.logical_pred.fcout.3.layers.0.bias: copying a param with shape torch.Size([9]) from checkpoint, the shape in current model is torch.Size([18]).
	size mismatch for node_type_encoders.logical_pred.fcout.4.layers.0.weight: copying a param with shape torch.Size([128, 9]) from checkpoint, the shape in current model is torch.Size([128, 18]).
	size mismatch for node_type_encoders.logical_pred.embeddings.operator.embed.weight: copying a param with shape torch.Size([5, 5]) from checkpoint, the shape in current model is torch.Size([11, 11]).
[2024-04-20 20:00:55][INFO][train.py:272]:Starting validation for ../zero-shot-data/evaluation/train_on_c8220_test_on_qh1/test_imdb_0_index_workload_100k_s2_qh1.csv
[2024-04-20 20:00:55][INFO][train.py:276]:Reloading best model
Traceback (most recent call last):
  File "train.py", line 91, in <module>
    train_readout_hyperparams(logger, args.workload_runs, args.test_workload_runs, args.statistics_file, args.target,
  File "/home/wuy/DB/performance_estimation/zero-shot-cost-estimation/models/training/train.py", line 428, in train_readout_hyperparams
    train_model(logger, workload_runs, test_workload_runs, statistics_file, target_dir, filename_model,
  File "/home/wuy/DB/performance_estimation/zero-shot-cost-estimation/models/training/train.py", line 277, in train_model
    model.load_state_dict(early_stop_m.best_model)
  File "/home/wuy/software/anaconda3/envs/zsce/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1559, in load_state_dict
    raise TypeError("Expected state_dict to be dict-like, got {}.".format(type(state_dict)))
TypeError: Expected state_dict to be dict-like, got <class 'NoneType'>.
